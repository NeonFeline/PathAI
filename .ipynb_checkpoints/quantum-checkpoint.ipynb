{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "194dde63-8248-4c1b-8964-f47d61ac6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba389c-f057-4ff0-bacd-4cb231e84c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qailab.circuit import build_circuit, RotationalEncoder, CXEntangler, RealAmplitudesBlock\n",
    "\n",
    "input_encoder = RotationalEncoder('x','input')\n",
    "quantum_circuit = build_circuit(\n",
    "    3,\n",
    "    [\n",
    "        input_encoder,\n",
    "        CXEntangler(),\n",
    "        RealAmplitudesBlock('weight'),\n",
    "        input_encoder, #You can put the same block twice in different parts of the circuit. It will encode the same parameters\n",
    "        CXEntangler(),\n",
    "        RealAmplitudesBlock('weight')\n",
    "    ],\n",
    "    measure_qubits=[0,1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc3558-8db0-44ed-aa49-21391a3dbea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantumAttention, self).__init__()\n",
    "        self.input_encoder = RotationalEncoder('x','input')\n",
    "        self.qnn_circuit = build_circuit(\n",
    "            3,\n",
    "            [\n",
    "                self.input_encoder,\n",
    "                RealAmplitudesBlock('weight'),\n",
    "                self.input_encoder, # You can put the same block twice in different parts of the circuit. It will encode the same parameters\n",
    "            ],\n",
    "            measure_qubits=[0,1,2] # Measure all qubits\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40cebf9b-559b-481f-88e4-f02e12d9b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# from qailab.torch import QLayer\n",
    "\n",
    "# qlayer = QLayer(\n",
    "#     quantum_circuit,\n",
    "#     shots = 2048\n",
    "#     )\n",
    "\n",
    "# sequential_net = nn.Sequential(\n",
    "#     nn.Linear(4,qlayer.in_features),\n",
    "#     nn.ReLU(),\n",
    "#     qlayer,\n",
    "#     nn.Linear(qlayer.out_features,4),\n",
    "#     nn.Softmax()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f69658-61d0-4da3-929b-058e7c460a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# QNN library integrating with PyTorch\n",
    "from qailab.circuit import build_circuit, RotationalEncoder, RealAmplitudesBlock\n",
    "from qailab.circuit.utils import assign_input_weight\n",
    "\n",
    "input_encoder = RotationalEncoder('x','input')\n",
    "qnn_circuit = build_circuit(\n",
    "    3,\n",
    "    [\n",
    "        input_encoder,\n",
    "        RealAmplitudesBlock('weight'),\n",
    "        input_encoder, # You can put the same block twice in different parts of the circuit. It will encode the same parameters\n",
    "    ],\n",
    "    measure_qubits=[0,1,2] # Measure all qubits\n",
    "    )\n",
    "\n",
    "qnn_circuit.assign_parameters(assign_input_weight(qnn_circuit,[1,2,3],np.random.randint(0,9,12))).draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4608f015-6297-493a-a017-e7a143141d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qailab.torch import QLayer,QModel,orca_layer\n",
    "\n",
    "qlayer = orca_layer.ORCALayer(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c7dda-ae29-408a-a60a-dff6c2625141",
   "metadata": {},
   "outputs": [],
   "source": [
    "myParameters = torch.tensor([[5.8932],\n",
    "         [3.9148],\n",
    "         [1.7986],\n",
    "         [4.9899],\n",
    "         [3.6941],\n",
    "         [4.2348],\n",
    "         [2.7410],\n",
    "         [5.4953],\n",
    "         [3.0173],\n",
    "         [4.3170],\n",
    "         [2.2644],\n",
    "                             [1.1860]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0cfd9-1543-4848-a71e-cf87fe43df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "myParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f090d9ea-8ddb-4dc6-b328-3cef5d5ca52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORCALayer(\n",
       "  (pt_layer): PTLayer(in_features=3, output_observables=4, trainable_theta=0)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922fc8ef-1f55-4590-8d15-844d8b5ac99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x780e4c047140>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qlayer.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30f478f-34ce-4b2e-8df6-9bdb1187eff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in qlayer.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fbf0af4-53b9-4484-90d2-1588089cd581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in qlayer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c0d1b-9081-4692-ad75-465387e751ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grads = torch.stack([p.grad for p in qlayer.parameters()])\n",
    "print(param_grads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa11bb-4335-45d3-956b-bc18bf203065",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = qlayer(torch.tensor([1.0, 2.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e685e-dda6-4fd0-a6e1-3b8d431083c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217b431-72e3-4f81-8665-7028595e1de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5838ef32-5a84-4cbb-870e-f49164ac19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(out, torch.tensor([0.1299, 0.7953, 0.0088, 0.0078, 0.1670, 0.0000, 0.4814, 0.0098]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26cb7a9-9e3d-4181-a02f-cac83ace6155",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250fd789-3b90-44e4-9c0e-aff367e38709",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772c1566-341d-4547-a32b-12350750ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d9e6d433-2a35-43a4-9053-f6432784acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = orca_layer.ORCALayer(\n",
    "            in_features=2,\n",
    "            n_loops=2,\n",
    "            observable='avg-photons',\n",
    "            gradient_mode='parameter-shift',\n",
    "            n_samples=100,\n",
    "            \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "95f6d2f6-6f70-481d-828a-ed58107bca1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORCALayer(\n",
       "  (pt_layer): PTLayer(in_features=2, output_observables=3, trainable_theta=2)\n",
       ")"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8e01889e-6604-43e0-a765-9217cdacf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = test.forward(torch.tensor([[0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "43fa3a64-7de3-44d1-bc89-b1045dd06929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2700, 0.3487, 0.3812]], grad_fn=<TBIAutogradBackward>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37ee3b-8348-4242-bb56-2d9b82ffa127",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(self, classical_input_size, classical_hidden_size, orca_in_features):\n",
    "        super(HybridNetwork, self).__init__()\n",
    "        \n",
    "        # Classical feature extraction network\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(classical_input_size, classical_hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Network to generate ORCA input data\n",
    "        self.orca_input_generator = nn.Linear(classical_hidden_size, orca_in_features)\n",
    "        \n",
    "        # Network to generate ORCA parameters (thetas)\n",
    "        self.orca_param_generator = nn.Linear(classical_hidden_size, orca_in_features)\n",
    "        \n",
    "        # ORCA quantum layer\n",
    "        self.orca_layer = orca_layer.ORCALayer(\n",
    "            in_features=orca_in_features,\n",
    "            observable='avg-photons',\n",
    "            gradient_mode='parameter-shift',\n",
    "            n_samples=100,\n",
    "            n_loops=2,\n",
    "        )\n",
    "    \n",
    "    def forward(self, query, key):\n",
    "        # Extract features from input\n",
    "        features = self.feature_extractor(query)\n",
    "        print(features.shape)\n",
    "        # Generate ORCA input data\n",
    "        orca_inputs = self.orca_input_generator(features)\n",
    "        print(orca_inputs.shape)\n",
    "        # Generate dynamic parameters for ORCA layer\n",
    "        theta_params = self.orca_param_generator(features)\n",
    "        print(theta_params.shape)\n",
    "        # Update ORCA parameters\n",
    "        self.orca_layer.set_thetas(key)\n",
    "        print(theta_params.shape)\n",
    "        # Process through quantum layer\n",
    "        quantum_output = self.orca_layer(orca_inputs)\n",
    "        print(quantum_output.shape)\n",
    "        \n",
    "        return quantum_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "af5ef12f-d949-4199-ad3b-7c4aeedac3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridNetwork(nn.Module):\n",
    "    def __init__(self, classical_input_size, classical_hidden_size, orca_in_features):\n",
    "        super(HybridNetwork, self).__init__()\n",
    "        \n",
    "        # Classical feature extraction network\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(classical_input_size, classical_hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Network to generate ORCA input data\n",
    "        self.orca_input_generator = nn.Linear(classical_hidden_size, orca_in_features)\n",
    "        \n",
    "        # ORCA quantum layer\n",
    "        self.orca_layer = orca_layer.ORCALayer(\n",
    "            in_features=orca_in_features,\n",
    "            observable='avg-photons',\n",
    "            gradient_mode='parameter-shift',\n",
    "            n_samples=100,\n",
    "            n_loops=2,\n",
    "        )\n",
    "        \n",
    "        # Initialize a parameter buffer to store original key gradients\n",
    "        self.register_buffer('orig_key', None)\n",
    "        self.key_requires_grad = False\n",
    "    \n",
    "    def forward(self, query, key):\n",
    "        # Save the original key tensor and its requires_grad state\n",
    "        self.orig_key = key\n",
    "        self.key_requires_grad = key.requires_grad\n",
    "        \n",
    "        # Extract features from input\n",
    "        features = self.feature_extractor(query)\n",
    "        \n",
    "        # Generate ORCA input data\n",
    "        orca_inputs = self.orca_input_generator(features)\n",
    "        \n",
    "        # Update ORCA parameters with the key\n",
    "        self.orca_layer.set_thetas(key)\n",
    "        \n",
    "        # Register a hook for backward to capture gradients\n",
    "        if self.key_requires_grad:\n",
    "            # Get the parameter that was set in the ORCA layer\n",
    "            for param in self.orca_layer.parameters():\n",
    "                if param.shape == key.shape:\n",
    "                    param.register_hook(lambda grad: self._save_grad_to_key(grad))\n",
    "        \n",
    "        # Process through quantum layer\n",
    "        quantum_output = self.orca_layer(orca_inputs)\n",
    "        \n",
    "        return quantum_output\n",
    "    \n",
    "    def _save_grad_to_key(self, grad):\n",
    "        # This function will be called during backward pass\n",
    "        # It passes the gradient from the ORCA parameters back to the original key\n",
    "        if self.orig_key.grad is None:\n",
    "            self.orig_key.grad = grad.clone()\n",
    "        else:\n",
    "            self.orig_key.grad += grad.clone()\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "799b3205-2ac1-428e-8a10-632f2c287d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumAttention(nn.Module):\n",
    "    def __init__(self, classical_input_size, orca_in_features, orca_out_features):\n",
    "        super(QuantumAttention, self).__init__()\n",
    "        \n",
    "\n",
    "        self.keyMatrix = nn.Linear(classical_input_size, orca_in_features)\n",
    "        self.queryMatrix = nn.Linear(classical_input_size, orca_in_features)\n",
    "        self.valueMatrix = nn.Linear(classical_input_size, orca_out_features) \n",
    "\n",
    "        \n",
    "        \n",
    "        # ORCA quantum layer\n",
    "        self.orca_layer = orca_layer.ORCALayer(\n",
    "            in_features=orca_in_features,\n",
    "            observable='avg-photons',\n",
    "            gradient_mode='parameter-shift',\n",
    "            n_samples=100,\n",
    "            n_loops=2,\n",
    "        )\n",
    "        \n",
    "        # Initialize a parameter buffer to store original key gradients\n",
    "        self.register_buffer('orig_key', None)\n",
    "        self.key_requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Save the original key tensor and its requires_grad state\n",
    "        key = self.keyMatrix(x)\n",
    "        querry = self.queryMatrix(x)\n",
    "        value = self.valueMatrix(x)\n",
    "        \n",
    "        self.orig_key = key\n",
    "        self.key_requires_grad = key.requires_grad\n",
    "        \n",
    "        # Update ORCA parameters with the key\n",
    "        self.orca_layer.set_thetas(key)\n",
    "        \n",
    "        # Register a hook for backward to capture gradients\n",
    "        if self.key_requires_grad:\n",
    "            # Get the parameter that was set in the ORCA layer\n",
    "            for param in self.orca_layer.parameters():\n",
    "                if param.shape == key.shape:\n",
    "                    param.register_hook(lambda grad: self._save_grad_to_key(grad))\n",
    "        \n",
    "        # Process through quantum layer\n",
    "        key_querry = self.orca_layer(querry)\n",
    "\n",
    "        output = key_querry * value\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def _save_grad_to_key(self, grad):\n",
    "        # This function will be called during backward pass\n",
    "        # It passes the gradient from the ORCA parameters back to the original key\n",
    "        if self.orig_key.grad is None:\n",
    "            self.orig_key.grad = grad.clone()\n",
    "        else:\n",
    "            self.orig_key.grad += grad.clone()\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "cf4fe698-feba-44b6-b841-ab874bf09dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qlayer = QuantumAttention(4, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "a0043efd-5f42-47f4-8043-393727f20f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0794,  0.0627, -0.0559,  0.2136]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qlayer(torch.tensor([[0.1, 0.2, 0.3, 0.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "c8633d38-a1aa-4285-8244-60fc11755d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = HybridNetwork(4,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "a95ae9ae-89a9-4330-9000-8359f0eef058",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([[0.1, 0.2, 0.3, 0.5]])\n",
    "inp.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "04493596-3af8-4fb6-882c-6a892c3559e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000, 0.3000, 0.5000]], requires_grad=True)"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "c82b4639-2f45-4895-88fe-fe40d3bbf46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4915, 0.1025, 0.1986, 0.0998]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qlayer(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "55e3ffc2-2cbe-408d-9fd0-c3ce88e9c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "testik = torch.tensor([-0.2,0.2,0.2])\n",
    "testik.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "389518f3-0281-45b4-b620-121ec84b749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(qlayer.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "c05f9fbe-f95d-43ed-8e6e-8c37bb0ab365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23832/1767083542.py:55: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  if self.orig_key.grad is None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06554163992404938\n",
      "0.03753373771905899\n",
      "0.01209742296487093\n",
      "0.0019512844737619162\n",
      "0.0001293780660489574\n",
      "2.563702582847327e-05\n",
      "4.7615387302357703e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[538]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10000\u001b[39m):\n\u001b[32m      2\u001b[39m     optimizer.zero_grad()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     out = \u001b[43mqlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     loss = torch.mean((out-torch.tensor([\u001b[32m0.5\u001b[39m, \u001b[32m0.1\u001b[39m, \u001b[32m0.2\u001b[39m, \u001b[32m0.1\u001b[39m]))**\u001b[32m2\u001b[39m)\n\u001b[32m      5\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[492]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mQuantumAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     43\u001b[39m             param.register_hook(\u001b[38;5;28;01mlambda\u001b[39;00m grad: \u001b[38;5;28mself\u001b[39m._save_grad_to_key(grad))\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Process through quantum layer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m key_querry = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43morca_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquerry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m output = key_querry * value\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/qailab/torch/orca_layer.py:80\u001b[39m, in \u001b[36mORCALayer.forward\u001b[39m\u001b[34m(self, x, n_samples)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, n_samples: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> torch.Tensor:\n\u001b[32m     66\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"ORCA layer pytorch Module forward method\u001b[39;00m\n\u001b[32m     67\u001b[39m \n\u001b[32m     68\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     78\u001b[39m \u001b[33;03m        layer output tensor\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpt_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/ptseries/models/pt_layer.py:195\u001b[39m, in \u001b[36mPTLayer.forward\u001b[39m\u001b[34m(self, x, n_samples)\u001b[39m\n\u001b[32m    192\u001b[39m         \u001b[38;5;66;03m# concatenate each of these new subtensors\u001b[39;00m\n\u001b[32m    193\u001b[39m         x = torch.cat(tile_subs, \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTBIAutograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobservable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtbi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m TBIAutograd.apply(x, \u001b[38;5;28mself\u001b[39m.observable, \u001b[38;5;28mself\u001b[39m.tbi, parameters)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/torch/autograd/function.py:575\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    574\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/ptseries/models/pt_layer.py:425\u001b[39m, in \u001b[36mTBIAutograd.forward\u001b[39m\u001b[34m(ctx, theta_angles, observable_function, tbi, parameters)\u001b[39m\n\u001b[32m    422\u001b[39m     samples_copy = [\u001b[38;5;28mtuple\u001b[39m(state) \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m samples_copy]\n\u001b[32m    423\u001b[39m     state_counts = Counter(samples_copy)\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m upshifted_observable = \u001b[43mobservable_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    426\u001b[39m upshifted_expectation[i, start_idx + j, :] = upshifted_observable\n\u001b[32m    428\u001b[39m theta_list[j] -= \u001b[32m2\u001b[39m * gradient_delta\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/ptseries/models/observables.py:14\u001b[39m, in \u001b[36mObservable.__call__\u001b[39m\u001b[34m(self, measurements)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, measurements: \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeasurements\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/ptseries/models/observables.py:156\u001b[39m, in \u001b[36mAvgPhotons.estimate\u001b[39m\u001b[34m(self, measurements)\u001b[39m\n\u001b[32m    147\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns tensor of average photons per mode.\u001b[39;00m\n\u001b[32m    148\u001b[39m \n\u001b[32m    149\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m \u001b[33;03m    1d tensor with values of the average photon numbers\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    155\u001b[39m photons_per_mode = np.sum([np.asarray(state) * counts \u001b[38;5;28;01mfor\u001b[39;00m state, counts \u001b[38;5;129;01min\u001b[39;00m measurements.items()], axis=\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m avg_photons_per_mode = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphotons_per_mode\u001b[49m\u001b[43m)\u001b[49m / \u001b[38;5;28msum\u001b[39m(counts \u001b[38;5;28;01mfor\u001b[39;00m counts \u001b[38;5;129;01min\u001b[39;00m measurements.values())\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m avg_photons_per_mode\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    out = qlayer(inp)\n",
    "    loss = torch.mean((out-torch.tensor([0.5, 0.1, 0.2, 0.1]))**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%100 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "17e461fe-4793-4e9d-9b32-a1d1683e1647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "edff3863-34da-4d1e-a52f-7ace90286398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "354e0897-0bcc-4ccd-ab97-351e9009715b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1821, -0.0447, -0.0288])\n"
     ]
    }
   ],
   "source": [
    "for p in layer.orca_layer.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "3b52bba8-e7a3-45f0-8e03-82ee15150e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2095, 0.1204, 0.4037, 0.4919]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "b11fa48b-2709-429d-ba3a-e4dcc6d98e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2529, -0.5077, -0.7002])"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testik.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309033d7-43c2-4634-80f9-78ec4aeb23ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b69fe-d406-48e3-a7be-1fba4ab77c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
