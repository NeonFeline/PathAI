{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "194dde63-8248-4c1b-8964-f47d61ac6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba389c-f057-4ff0-bacd-4cb231e84c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qailab.circuit import build_circuit, RotationalEncoder, CXEntangler, RealAmplitudesBlock\n",
    "\n",
    "input_encoder = RotationalEncoder('x','input')\n",
    "quantum_circuit = build_circuit(\n",
    "    3,\n",
    "    [\n",
    "        input_encoder,\n",
    "        CXEntangler(),\n",
    "        RealAmplitudesBlock('weight'),\n",
    "        input_encoder, #You can put the same block twice in different parts of the circuit. It will encode the same parameters\n",
    "        CXEntangler(),\n",
    "        RealAmplitudesBlock('weight')\n",
    "    ],\n",
    "    measure_qubits=[0,1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc3558-8db0-44ed-aa49-21391a3dbea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantumAttention, self).__init__()\n",
    "        self.input_encoder = RotationalEncoder('x','input')\n",
    "        self.qnn_circuit = build_circuit(\n",
    "            3,\n",
    "            [\n",
    "                self.input_encoder,\n",
    "                RealAmplitudesBlock('weight'),\n",
    "                self.input_encoder, # You can put the same block twice in different parts of the circuit. It will encode the same parameters\n",
    "            ],\n",
    "            measure_qubits=[0,1,2] # Measure all qubits\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40cebf9b-559b-481f-88e4-f02e12d9b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# from qailab.torch import QLayer\n",
    "\n",
    "# qlayer = QLayer(\n",
    "#     quantum_circuit,\n",
    "#     shots = 2048\n",
    "#     )\n",
    "\n",
    "# sequential_net = nn.Sequential(\n",
    "#     nn.Linear(4,qlayer.in_features),\n",
    "#     nn.ReLU(),\n",
    "#     qlayer,\n",
    "#     nn.Linear(qlayer.out_features,4),\n",
    "#     nn.Softmax()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f69658-61d0-4da3-929b-058e7c460a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# QNN library integrating with PyTorch\n",
    "from qailab.circuit import build_circuit, RotationalEncoder, RealAmplitudesBlock\n",
    "from qailab.circuit.utils import assign_input_weight\n",
    "\n",
    "input_encoder = RotationalEncoder('x','input')\n",
    "qnn_circuit = build_circuit(\n",
    "    3,\n",
    "    [\n",
    "        input_encoder,\n",
    "        RealAmplitudesBlock('weight'),\n",
    "        input_encoder, # You can put the same block twice in different parts of the circuit. It will encode the same parameters\n",
    "    ],\n",
    "    measure_qubits=[0,1,2] # Measure all qubits\n",
    "    )\n",
    "\n",
    "qnn_circuit.assign_parameters(assign_input_weight(qnn_circuit,[1,2,3],np.random.randint(0,9,12))).draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4608f015-6297-493a-a017-e7a143141d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qailab.torch import QLayer,QModel,orca_layer\n",
    "\n",
    "qlayer = orca_layer.ORCALayer(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c7dda-ae29-408a-a60a-dff6c2625141",
   "metadata": {},
   "outputs": [],
   "source": [
    "myParameters = torch.tensor([[5.8932],\n",
    "         [3.9148],\n",
    "         [1.7986],\n",
    "         [4.9899],\n",
    "         [3.6941],\n",
    "         [4.2348],\n",
    "         [2.7410],\n",
    "         [5.4953],\n",
    "         [3.0173],\n",
    "         [4.3170],\n",
    "         [2.2644],\n",
    "                             [1.1860]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a0cfd9-1543-4848-a71e-cf87fe43df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "myParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "944ee211-28f9-4135-a43b-9ab28ec68850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QuantumSelfAttentionLayer import QuantumSelfAttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "922fc8ef-1f55-4590-8d15-844d8b5ac99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qlayer = QuantumSelfAttentionLayer(100, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "e30f478f-34ce-4b2e-8df6-9bdb1187eff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-2.1227e-01, -8.9329e-03,  1.1817e-01, -8.4667e-02,  6.8146e-02,\n",
      "         -3.9404e-01],\n",
      "        [ 1.3474e-01,  2.5167e-01,  2.8205e-01, -3.5767e-01,  2.5497e-01,\n",
      "         -1.8302e-02],\n",
      "        [-3.6671e-01, -1.5116e-04,  2.0924e-01, -3.9760e-01,  2.9678e-01,\n",
      "         -2.7937e-02],\n",
      "        [-4.4876e-02, -1.1559e-01, -1.2271e-01,  4.0002e-01, -5.9956e-03,\n",
      "         -6.8764e-03]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3266,  0.2892,  0.0421,  0.0387], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1544, -0.1220, -0.3578,  0.2040,  0.3957,  0.1728],\n",
      "        [-0.0359,  0.0718, -0.3407, -0.0406, -0.3325,  0.2524],\n",
      "        [ 0.3298, -0.3969,  0.3754,  0.3771,  0.2182,  0.0167],\n",
      "        [-0.3879, -0.1830,  0.0296,  0.2537,  0.2221, -0.2555]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1610, 0.1588, 0.0054, 0.3238], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1667,  0.1307,  0.2567, -0.2578, -0.1818,  0.1253],\n",
      "        [ 0.0314,  0.0179, -0.2118, -0.3530,  0.2705,  0.3551],\n",
      "        [ 0.2496, -0.2816, -0.2480, -0.0944,  0.2975,  0.2917],\n",
      "        [-0.1880,  0.3066,  0.1843, -0.0773,  0.2762,  0.0562],\n",
      "        [-0.1297, -0.2128, -0.1601,  0.1357, -0.1088,  0.2126]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3529,  0.3811, -0.0558, -0.0759, -0.3970], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.3112, 1.2685, 0.9799, 1.8139]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in qlayer.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "1fbf0af4-53b9-4484-90d2-1588089cd581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-2.1227e-01, -8.9329e-03,  1.1817e-01, -8.4667e-02,  6.8146e-02,\n",
       "          -3.9404e-01],\n",
       "         [ 1.3474e-01,  2.5167e-01,  2.8205e-01, -3.5767e-01,  2.5497e-01,\n",
       "          -1.8302e-02],\n",
       "         [-3.6671e-01, -1.5116e-04,  2.0924e-01, -3.9760e-01,  2.9678e-01,\n",
       "          -2.7937e-02],\n",
       "         [-4.4876e-02, -1.1559e-01, -1.2271e-01,  4.0002e-01, -5.9956e-03,\n",
       "          -6.8764e-03]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3266,  0.2892,  0.0421,  0.0387], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1544, -0.1220, -0.3578,  0.2040,  0.3957,  0.1728],\n",
       "         [-0.0359,  0.0718, -0.3407, -0.0406, -0.3325,  0.2524],\n",
       "         [ 0.3298, -0.3969,  0.3754,  0.3771,  0.2182,  0.0167],\n",
       "         [-0.3879, -0.1830,  0.0296,  0.2537,  0.2221, -0.2555]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1610, 0.1588, 0.0054, 0.3238], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.1667,  0.1307,  0.2567, -0.2578, -0.1818,  0.1253],\n",
       "         [ 0.0314,  0.0179, -0.2118, -0.3530,  0.2705,  0.3551],\n",
       "         [ 0.2496, -0.2816, -0.2480, -0.0944,  0.2975,  0.2917],\n",
       "         [-0.1880,  0.3066,  0.1843, -0.0773,  0.2762,  0.0562],\n",
       "         [-0.1297, -0.2128, -0.1601,  0.1357, -0.1088,  0.2126]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3529,  0.3811, -0.0558, -0.0759, -0.3970], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[1.3112, 1.2685, 0.9799, 1.8139]], requires_grad=True)]"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in qlayer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "217c0d1b-9081-4692-ad75-465387e751ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[568]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m param_grads = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mqlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(param_grads)\n",
      "\u001b[31mTypeError\u001b[39m: expected Tensor as element 0 in argument 0, but got NoneType"
     ]
    }
   ],
   "source": [
    "param_grads = torch.stack([p.grad for p in qlayer.parameters()])\n",
    "print(param_grads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "57aa11bb-4335-45d3-956b-bc18bf203065",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = qlayer(torch.tensor([[1.0, 2.0, 1.0, 0.0, 0.1, 0.2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "949e685e-dda6-4fd0-a6e1-3b8d431083c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0705,  0.0567, -0.3282,  0.4262, -0.2790]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217b431-72e3-4f81-8665-7028595e1de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5838ef32-5a84-4cbb-870e-f49164ac19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_fn(out, torch.tensor([0.1299, 0.7953, 0.0088, 0.0078, 0.1670, 0.0000, 0.4814, 0.0098]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26cb7a9-9e3d-4181-a02f-cac83ace6155",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250fd789-3b90-44e4-9c0e-aff367e38709",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772c1566-341d-4547-a32b-12350750ee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d9e6d433-2a35-43a4-9053-f6432784acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = orca_layer.ORCALayer(\n",
    "            in_features=2,\n",
    "            n_loops=2,\n",
    "            observable='avg-photons',\n",
    "            gradient_mode='parameter-shift',\n",
    "            n_samples=100,\n",
    "            \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "95f6d2f6-6f70-481d-828a-ed58107bca1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORCALayer(\n",
       "  (pt_layer): PTLayer(in_features=2, output_observables=3, trainable_theta=2)\n",
       ")"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8e01889e-6604-43e0-a765-9217cdacf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = test.forward(torch.tensor([[0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "43fa3a64-7de3-44d1-bc89-b1045dd06929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2700, 0.3487, 0.3812]], grad_fn=<TBIAutogradBackward>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37ee3b-8348-4242-bb56-2d9b82ffa127",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(self, classical_input_size, classical_hidden_size, orca_in_features):\n",
    "        super(HybridNetwork, self).__init__()\n",
    "        \n",
    "        # Classical feature extraction network\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(classical_input_size, classical_hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Network to generate ORCA input data\n",
    "        self.orca_input_generator = nn.Linear(classical_hidden_size, orca_in_features)\n",
    "        \n",
    "        # Network to generate ORCA parameters (thetas)\n",
    "        self.orca_param_generator = nn.Linear(classical_hidden_size, orca_in_features)\n",
    "        \n",
    "        # ORCA quantum layer\n",
    "        self.orca_layer = orca_layer.ORCALayer(\n",
    "            in_features=orca_in_features,\n",
    "            observable='avg-photons',\n",
    "            gradient_mode='parameter-shift',\n",
    "            n_samples=100,\n",
    "            n_loops=2,\n",
    "        )\n",
    "    \n",
    "    def forward(self, query, key):\n",
    "        # Extract features from input\n",
    "        features = self.feature_extractor(query)\n",
    "        print(features.shape)\n",
    "        # Generate ORCA input data\n",
    "        orca_inputs = self.orca_input_generator(features)\n",
    "        print(orca_inputs.shape)\n",
    "        # Generate dynamic parameters for ORCA layer\n",
    "        theta_params = self.orca_param_generator(features)\n",
    "        print(theta_params.shape)\n",
    "        # Update ORCA parameters\n",
    "        self.orca_layer.set_thetas(key)\n",
    "        print(theta_params.shape)\n",
    "        # Process through quantum layer\n",
    "        quantum_output = self.orca_layer(orca_inputs)\n",
    "        print(quantum_output.shape)\n",
    "        \n",
    "        return quantum_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "af5ef12f-d949-4199-ad3b-7c4aeedac3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridNetwork(nn.Module):\n",
    "    def __init__(self, classical_input_size, classical_hidden_size, orca_in_features):\n",
    "        super(HybridNetwork, self).__init__()\n",
    "        \n",
    "        # Classical feature extraction network\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(classical_input_size, classical_hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Network to generate ORCA input data\n",
    "        self.orca_input_generator = nn.Linear(classical_hidden_size, orca_in_features)\n",
    "        \n",
    "        # ORCA quantum layer\n",
    "        self.orca_layer = orca_layer.ORCALayer(\n",
    "            in_features=orca_in_features,\n",
    "            observable='avg-photons',\n",
    "            gradient_mode='parameter-shift',\n",
    "            n_samples=100,\n",
    "            n_loops=2,\n",
    "        )\n",
    "        \n",
    "        # Initialize a parameter buffer to store original key gradients\n",
    "        self.register_buffer('orig_key', None)\n",
    "        self.key_requires_grad = False\n",
    "    \n",
    "    def forward(self, query, key):\n",
    "        # Save the original key tensor and its requires_grad state\n",
    "        self.orig_key = key\n",
    "        self.key_requires_grad = key.requires_grad\n",
    "        \n",
    "        # Extract features from input\n",
    "        features = self.feature_extractor(query)\n",
    "        \n",
    "        # Generate ORCA input data\n",
    "        orca_inputs = self.orca_input_generator(features)\n",
    "        \n",
    "        # Update ORCA parameters with the key\n",
    "        self.orca_layer.set_thetas(key)\n",
    "        \n",
    "        # Register a hook for backward to capture gradients\n",
    "        if self.key_requires_grad:\n",
    "            # Get the parameter that was set in the ORCA layer\n",
    "            for param in self.orca_layer.parameters():\n",
    "                if param.shape == key.shape:\n",
    "                    param.register_hook(lambda grad: self._save_grad_to_key(grad))\n",
    "        \n",
    "        # Process through quantum layer\n",
    "        quantum_output = self.orca_layer(orca_inputs)\n",
    "        \n",
    "        return quantum_output\n",
    "    \n",
    "    def _save_grad_to_key(self, grad):\n",
    "        # This function will be called during backward pass\n",
    "        # It passes the gradient from the ORCA parameters back to the original key\n",
    "        if self.orig_key.grad is None:\n",
    "            self.orig_key.grad = grad.clone()\n",
    "        else:\n",
    "            self.orig_key.grad += grad.clone()\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "799b3205-2ac1-428e-8a10-632f2c287d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumAttention(nn.Module):\n",
    "    def __init__(self, classical_input_size, orca_in_features, orca_out_features):\n",
    "        super(QuantumAttention, self).__init__()\n",
    "        \n",
    "\n",
    "        self.keyMatrix = nn.Linear(classical_input_size, orca_in_features)\n",
    "        self.queryMatrix = nn.Linear(classical_input_size, orca_in_features)\n",
    "        self.valueMatrix = nn.Linear(classical_input_size, orca_out_features) \n",
    "\n",
    "        \n",
    "        \n",
    "        # ORCA quantum layer\n",
    "        self.orca_layer = orca_layer.ORCALayer(\n",
    "            in_features=orca_in_features,\n",
    "            observable='avg-photons',\n",
    "            gradient_mode='parameter-shift',\n",
    "            n_samples=100,\n",
    "            n_loops=2,\n",
    "        )\n",
    "        \n",
    "        # Initialize a parameter buffer to store original key gradients\n",
    "        self.register_buffer('orig_query', None)\n",
    "        self.query_requires_grad = False\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Save the original key tensor and its requires_grad state\n",
    "        key = self.keyMatrix(x)\n",
    "        query = self.queryMatrix(x)\n",
    "        value = self.valueMatrix(x)\n",
    "        \n",
    "        self.orig_query = query\n",
    "        self.query_requires_grad = query.requires_grad\n",
    "        \n",
    "        # Update ORCA parameters with the key\n",
    "        self.orca_layer.set_thetas(query)\n",
    "        \n",
    "        # Register a hook for backward to capture gradients\n",
    "        if self.query_requires_grad:\n",
    "            # Get the parameter that was set in the ORCA layer\n",
    "            for param in self.orca_layer.parameters():\n",
    "                if param.shape == query.shape:\n",
    "                    param.register_hook(lambda grad: self._save_grad_to_query(grad))\n",
    "        \n",
    "        # Process through quantum layer\n",
    "        key_querry = self.orca_layer(key)\n",
    "\n",
    "        output = key_querry * value\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def _save_grad_to_query(self, grad):\n",
    "        # This function will be called during backward pass\n",
    "        # It passes the gradient from the ORCA parameters back to the original key\n",
    "        if self.orig_query.grad is None:\n",
    "            self.orig_query.grad = grad.clone()\n",
    "        else:\n",
    "            self.orig_query.grad += grad.clone()\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "cf4fe698-feba-44b6-b841-ab874bf09dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qlayer = QuantumAttention(4, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "a0043efd-5f42-47f4-8043-393727f20f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1177, -0.0432, -0.0091, -0.2074]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qlayer(torch.tensor([[0.1, 0.2, 0.3, 0.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "c8633d38-a1aa-4285-8244-60fc11755d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = HybridNetwork(4,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "a95ae9ae-89a9-4330-9000-8359f0eef058",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([[0.1, 0.2, 0.3, 0.5]])\n",
    "inp.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "04493596-3af8-4fb6-882c-6a892c3559e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000, 0.3000, 0.5000]], requires_grad=True)"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "c82b4639-2f45-4895-88fe-fe40d3bbf46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4844, 0.0979, 0.2054, 0.1000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qlayer(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "55e3ffc2-2cbe-408d-9fd0-c3ce88e9c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "testik = torch.tensor([-0.2,0.2,0.2])\n",
    "testik.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "389518f3-0281-45b4-b620-121ec84b749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(qlayer.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "c05f9fbe-f95d-43ed-8e6e-8c37bb0ab365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23832/3348060093.py:54: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n",
      "  if self.orig_query.grad is None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07637156546115875\n",
      "0.02252538688480854\n",
      "0.0034922384656965733\n",
      "0.0007740415167063475\n",
      "0.00022456367150880396\n",
      "5.3255422244546935e-05\n",
      "2.0279419914004393e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_23832/737111166.py\", line 3, in <module>\n",
      "    out = qlayer(inp)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_23832/3348060093.py\", line 45, in forward\n",
      "    key_querry = self.orca_layer(key)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/qailab/torch/orca_layer.py\", line 80, in forward\n",
      "    return self.pt_layer.forward(x, n_samples)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/ptseries/models/pt_layer.py\", line 195, in forward\n",
      "    return TBIAutograd.apply(x, self.observable, self.tbi, parameters)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/torch/aException ignored in: 'zmq.backend.cython._zmq.Frame.__dealloc__'\n",
      "Traceback (most recent call last):\n",
      "  File \"_zmq.py\", line 169, in zmq.backend.cython._zmq._check_rc\n",
      "utograd/function.py\", line 575, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/ptseries/models/pt_layer.py\", line 430, in forward\n",
      "    state_counts = tbi.sample(\n",
      "                   ^^^^^^^^^^^\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/ptseries/tbi/tbi_multi_loop.py\", line 149, in sample\n",
      "    return self.format_samples(raw_samples, output_format=output_format)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/ptseries/tbi/tbi_abstract.py\", line 247, in format_samples\n",
      "    return {tuple(i.tolist()): int(j) for i, j in zip(*np.unique(samples, axis=0, return_counts=True))}\n",
      "                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/numpy/lib/_arraysetops_impl.py\", line 331, in unique\n",
      "    output = _unique1d(consolidated, return_index,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/numpy/lib/_arraysetops_impl.py\", line 380, in _unique1d\n",
      "    idx = np.concatenate(np.nonzero(mask) + ([mask.size],))\n",
      "                         ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/maciej/miniconda3/envs/medi/lib/python3.12/site-packages/numpy/_core/fromnumeric.py\", line 2014, in _nonzero_dispatcher\n",
      "    def _nonzero_dispatcher(a):\n",
      "    \n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"_zmq.py\", line 169, in zmq.backend.cython._zmq._check_rc\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[550]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10000\u001b[39m):\n\u001b[32m      2\u001b[39m     optimizer.zero_grad()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     out = \u001b[43mqlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     loss = torch.mean((out-torch.tensor([\u001b[32m0.5\u001b[39m, \u001b[32m0.1\u001b[39m, \u001b[32m0.2\u001b[39m, \u001b[32m0.1\u001b[39m]))**\u001b[32m2\u001b[39m)\n\u001b[32m      5\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[546]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mQuantumAttention.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     42\u001b[39m             param.register_hook(\u001b[38;5;28;01mlambda\u001b[39;00m grad: \u001b[38;5;28mself\u001b[39m._save_grad_to_query(grad))\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Process through quantum layer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m key_querry = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43morca_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m output = key_querry * value\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/qailab/torch/orca_layer.py:80\u001b[39m, in \u001b[36mORCALayer.forward\u001b[39m\u001b[34m(self, x, n_samples)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, n_samples: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> torch.Tensor:\n\u001b[32m     66\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"ORCA layer pytorch Module forward method\u001b[39;00m\n\u001b[32m     67\u001b[39m \n\u001b[32m     68\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     78\u001b[39m \u001b[33;03m        layer output tensor\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpt_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/ptseries/models/pt_layer.py:195\u001b[39m, in \u001b[36mPTLayer.forward\u001b[39m\u001b[34m(self, x, n_samples)\u001b[39m\n\u001b[32m    192\u001b[39m         \u001b[38;5;66;03m# concatenate each of these new subtensors\u001b[39;00m\n\u001b[32m    193\u001b[39m         x = torch.cat(tile_subs, \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTBIAutograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobservable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtbi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m TBIAutograd.apply(x, \u001b[38;5;28mself\u001b[39m.observable, \u001b[38;5;28mself\u001b[39m.tbi, parameters)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/torch/autograd/function.py:575\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    573\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    574\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    579\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    580\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    582\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    583\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/ptseries/models/pt_layer.py:430\u001b[39m, in \u001b[36mTBIAutograd.forward\u001b[39m\u001b[34m(ctx, theta_angles, observable_function, tbi, parameters)\u001b[39m\n\u001b[32m    426\u001b[39m upshifted_expectation[i, start_idx + j, :] = upshifted_observable\n\u001b[32m    428\u001b[39m theta_list[j] -= \u001b[32m2\u001b[39m * gradient_delta\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m state_counts = \u001b[43mtbi\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtheta_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_format\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_tiling > \u001b[32m1\u001b[39m:\n\u001b[32m    435\u001b[39m     samples_copy = samples_array.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/ptseries/tbi/tbi_multi_loop.py:149\u001b[39m, in \u001b[36mTBIMultiLoop.sample\u001b[39m\u001b[34m(self, input_state, theta_list, n_samples, output_format, n_tiling)\u001b[39m\n\u001b[32m    146\u001b[39m     temp_theta_list_len += theta_list_len\n\u001b[32m    147\u001b[39m     raw_samples[:, i * \u001b[38;5;28mself\u001b[39m.n_modes : (i + \u001b[32m1\u001b[39m) * \u001b[38;5;28mself\u001b[39m.n_modes] = samples\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/ptseries/tbi/tbi_abstract.py:247\u001b[39m, in \u001b[36mTBIBase.format_samples\u001b[39m\u001b[34m(samples, output_format)\u001b[39m\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m samples\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mtuple\u001b[39m(i.tolist()): \u001b[38;5;28mint\u001b[39m(j) \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(*\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/numpy/lib/_arraysetops_impl.py:331\u001b[39m, in \u001b[36munique\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[39m\n\u001b[32m    328\u001b[39m     uniq = np.moveaxis(uniq, \u001b[32m0\u001b[39m, axis)\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m uniq\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m output = \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconsolidated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43minverse_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m                   \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m output = (reshape_uniq(output[\u001b[32m0\u001b[39m]),) + output[\u001b[32m1\u001b[39m:]\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/numpy/lib/_arraysetops_impl.py:380\u001b[39m, in \u001b[36m_unique1d\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, equal_nan, inverse_shape, axis)\u001b[39m\n\u001b[32m    378\u001b[39m     ret += (inv_idx.reshape(inverse_shape) \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m inv_idx,)\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_counts:\n\u001b[32m--> \u001b[39m\u001b[32m380\u001b[39m     idx = np.concatenate(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m + ([mask.size],))\n\u001b[32m    381\u001b[39m     ret += (np.diff(idx),)\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/medi/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:2014\u001b[39m, in \u001b[36m_nonzero_dispatcher\u001b[39m\u001b[34m(a)\u001b[39m\n\u001b[32m   2010\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2011\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m asanyarray(a).ravel(order=order)\n\u001b[32m-> \u001b[39m\u001b[32m2014\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_nonzero_dispatcher\u001b[39m(a):\n\u001b[32m   2015\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[32m   2018\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_nonzero_dispatcher)\n\u001b[32m   2019\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnonzero\u001b[39m(a):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    out = qlayer(inp)\n",
    "    loss = torch.mean((out-torch.tensor([0.5, 0.1, 0.2, 0.1]))**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%100 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "17e461fe-4793-4e9d-9b32-a1d1683e1647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "edff3863-34da-4d1e-a52f-7ace90286398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "354e0897-0bcc-4ccd-ab97-351e9009715b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1821, -0.0447, -0.0288])\n"
     ]
    }
   ],
   "source": [
    "for p in layer.orca_layer.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "3b52bba8-e7a3-45f0-8e03-82ee15150e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2095, 0.1204, 0.4037, 0.4919]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "b11fa48b-2709-429d-ba3a-e4dcc6d98e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2529, -0.5077, -0.7002])"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testik.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309033d7-43c2-4634-80f9-78ec4aeb23ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b69fe-d406-48e3-a7be-1fba4ab77c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
